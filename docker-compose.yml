version: "3.9"

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
    env_file:
      - .env
    volumes:
      - ./backend:/app
    restart: unless-stopped

  db:
    image: postgres:15
    env_file:
      - .env
    ports:
      - "5432:5432"             
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    restart: unless-stopped

  # Airflow 초기화 (정리된 버전)
  airflow-init:
    image: apache/airflow:3.0.6-python3.11
    entrypoint: /bin/bash
    command:
      - -c
      - |
        mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins
        chown -R airflow: /opt/airflow
        pip install apache-airflow-providers-standard
        pip install apache-airflow-providers-fab
        airflow db migrate
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:${POSTGRES_PASSWORD}@db:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__AUTH_MANAGER=airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
      - AIRFLOW__API_AUTH__JWT_SECRET=${AIRFLOW_FERNET_KEY}
    volumes:
      - ./airflow:/opt/airflow
    depends_on:
      - db
      - redis
    user: "0:0"

  # Airflow API 서버
  airflow-api-server:
    image: apache/airflow:3.0.6-python3.11
    command: api-server
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:${POSTGRES_PASSWORD}@db:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__AUTH_MANAGER=airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
      - AIRFLOW__API_AUTH__JWT_SECRET=${AIRFLOW_FERNET_KEY}
    volumes:
      - ./airflow:/opt/airflow
    depends_on:
      - airflow-init
    restart: unless-stopped

  airflow-scheduler:
    image: apache/airflow:3.0.6-python3.11
    command: scheduler
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:${POSTGRES_PASSWORD}@db:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__AUTH_MANAGER=airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
      - AIRFLOW__API_AUTH__JWT_SECRET=${AIRFLOW_FERNET_KEY}
    volumes:
      - ./airflow:/opt/airflow
    depends_on:
      - airflow-init
    restart: unless-stopped

  airflow-dag-processor:
    image: apache/airflow:3.0.6-python3.11
    command: dag-processor
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:${POSTGRES_PASSWORD}@db:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__AUTH_MANAGER=airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
      - AIRFLOW__API_AUTH__JWT_SECRET=${AIRFLOW_FERNET_KEY}
    volumes:
      - ./airflow:/opt/airflow
    depends_on:
      - airflow-init
    restart: unless-stopped

volumes:
  postgres_data: